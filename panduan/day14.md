Mantap, Arie! ğŸ‘¨â€ğŸ’»  
Kita lanjut ke **Hari ke-14** â€” hari **refactor & profesionalisasi** â€” dengan prinsip tetap:  
> **Kode jelas, struktur rapi, dan langsung bisa dipahami mantan sysadmin yang pindah jadi engineer.**

---

## ğŸ¯ **Hari 14: Refactor Proyek Jadi Struktur Modern (Siap Production & Portofolio)**

Tujuan hari ini:
- Ubah semua skrip harian jadi **struktur proyek profesional**:
  ```
  python-ai/
  â”œâ”€â”€ src/
  â”‚   â””â”€â”€ loganalyzer/     â† kode utama
  â”œâ”€â”€ tests/               â† nanti buat test
  â”œâ”€â”€ data/                â† data mentah & output
  â”œâ”€â”€ scripts/             â† helper CLI & cron
  â”œâ”€â”€ docs/                â† dokumentasi
  â”œâ”€â”€ requirements.txt
  â”œâ”€â”€ README.md
  â””â”€â”€ .env.example
  ```
- Ini adalah **standar industri** untuk proyek Python (dipakai di Google, Meta, startup, dll)
- Recruiter & engineer lain akan langsung **respect** kalau lihat struktur ini

Dan tetap: **tidak ada magic, penjelasan langsung di struktur folder**.

---

### ğŸ§± Kenapa Struktur Ini Penting?
| Folder | Analogi SysAdmin |
|--------|------------------|
| `src/` | `/usr/src/` â€” tempat kode sumber resmi |
| `scripts/` | `/usr/local/bin/` â€” skrip yang bisa dijalankan langsung |
| `data/` | `/var/lib/app/` â€” data aplikasi |
| `docs/` | `/usr/share/doc/` â€” dokumentasi |
| `tests/` | `systemd --test` â€” verifikasi sebelum deploy |

---

## ğŸ“‚ Langkah 1: Buat Struktur Folder

Dari root repo (`python-ai/`), jalankan:

```bash
mkdir -p \
  src/loganalyzer \
  scripts \
  data/raw \
  data/output \
  docs \
  tests
```

---

## ğŸ“„ Langkah 2: Pindahkan & Perbarui Kode Inti

### Pindahkan kode inti ke `src/loganalyzer/`

Buat file: **`src/loganalyzer/__init__.py`**  
*(file ini tandai folder sebagai Python package â€” biar bisa di-import)*

```python
# src/loganalyzer/__init__.py
# Kosong aja. Cuma penanda.
```

---

### Buat: **`src/loganalyzer/core.py`**

```python
import requests
import csv
import os
from typing import List, Dict, Any

# Validasi & parsing logikanya di sini â€” reusable
REQUIRED_FIELDS = {
    'id': int,
    'userId': int,
    'title': str,
    'body': str
}

def fetch_posts(url: str) -> List[Dict[str, Any]]:
    resp = requests.get(url, timeout=10)
    resp.raise_for_status()
    return resp.json()

def validate_record(record: Dict) -> bool:
    for field, expected_type in REQUIRED_FIELDS.items():
        if field not in record:
            return False
        val = record[field]
        if not isinstance(val, expected_type):
            if expected_type == int and isinstance(val, str) and val.isdigit():
                record[field] = int(val)
            else:
                return False
    return True

def save_to_csv(records: List[Dict], output_path: str):
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    fieldnames = list(REQUIRED_FIELDS.keys())
    with open(output_path, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(records)
```

---

## ğŸ“„ Langkah 3: Buat CLI di `scripts/run_pipeline.py`

```python
#!/usr/bin/env python3
# scripts/run_pipeline.py
import os
import sys
import logging
from dotenv import load_dotenv

# Pastikan bisa import dari src/
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from loganalyzer.core import fetch_posts, validate_record, save_to_csv

load_dotenv()

logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')

def main():
    API_URL = os.getenv("API_URL", "https://jsonplaceholder.typicode.com/posts")
    OUTPUT = os.getenv("OUTPUT_CSV", "data/output/posts.csv")

    try:
        data = fetch_posts(API_URL)
        valid = [r for r in data if validate_record(r.copy())]
        save_to_csv(valid, OUTPUT)
        logging.info(f"âœ… {len(valid)} record valid disimpan ke {OUTPUT}")
    except Exception as e:
        logging.error(f"ğŸ’¥ Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## ğŸ“„ Langkah 4: Update `.env.example`

Di root repo:

```env
API_URL=https://jsonplaceholder.typicode.com/posts
OUTPUT_CSV=data/output/posts.csv
```

---

## ğŸ“„ Langkah 5: Update `README.md` (Contoh Ringkas)

```markdown
# Log Analyzer & Data Pipeline

Proyek latihan 30 hari: mantan sysadmin jadi Data/Software Engineer.

## ğŸ“¦ Struktur
- `src/` â†’ kode utama
- `scripts/` â†’ CLI tools
- `data/` â†’ input/output
- `requirements.txt` â†’ dependensi

## â–¶ï¸ Cara Jalankan
```bash
pip install -r requirements.txt
cp .env.example .env
python scripts/run_pipeline.py
```

Output: `data/output/posts.csv`
```

---

### â–¶ï¸ Cara Uji:
```bash
# Salin .env
cp .env.example .env

# Jalankan
python scripts/run_pipeline.py
```

Cek: `data/output/posts.csv` â†’ harus ada!

---

## âœ… Tugas Hari Ini:
1. Buat struktur folder (`src/`, `scripts/`, `data/`, dll)
2. Pindahkan & refactor kode ke struktur baru
3. Pastikan `scripts/run_pipeline.py` jalan
4. **COMMIT & PUSH KE GITHUB!**  
   Ini adalah **titik balik**: dari "latihan harian" â†’ **proyek portofolio nyata**.

> Setelah selesai, balas: **â€œDay 14 done! ğŸ—ï¸ Proyek sudah rapi.â€**

Besok (Hari 15): kita tambahkan **unit test pertama** â€” biar kamu bisa pastikan kode tetap jalan saat diubah. Ini adalah **tanda engineer profesional**.

Ayo, Arie! **Jangan biarkan repo-mu tetap kosong.**  
Hari ini kamu **naik level** dari â€œcoderâ€ ke â€œengineerâ€. ğŸ’ª


Mantap, Arie!  
Struktur folder **Hari ke-14** kamu **sudah sangat bagus** â€” ini **sudah melebihi standar awal engineer junior**. Tapi karena kamu butuh **penilaian harian yang jelas**, kita buat **checklist eksplisit** + **cara uji langsung pakai bash**.

---

## âœ… **Checklist Penilaian Hari 14 (Refactor ke Struktur Profesional)**

| No | Item | Status |
|----|------|--------|
| 1 | Ada folder `src/` dengan package Python (`__init__.py`) | âœ… |
| 2 | Ada folder `scripts/` berisi CLI yang bisa dijalankan | âœ… |
| 3 | Ada folder `data/` (raw + output) untuk pisahkan data dari kode | âœ… |
| 4 | Ada `requirements.txt` | âœ… |
| 5 | Ada `README.md` yang menjelaskan cara pakai | âœ… |
| 6 | Kode inti (fetch + validasi) dipindah ke `src/loganalyzer/core.py` | âœ… |
| 7 | CLI di `scripts/run_pipeline.py` bisa jalan **tanpa error** | âš ï¸ **Perlu diuji!** |
| 8 | Proyek bisa dijalankan dari root dengan **1 perintah** | âš ï¸ **Perlu diuji!** |

> **Nilai sementara**: **90%**  
> Tinggal **uji eksekusi** â†’ kalau jalan, langsung **100%**.

---

## ğŸ› ï¸ **File yang Harus Ada (Final Checklist)**

### Wajib ada di root:
- [x] `README.md`
- [x] `requirements.txt`
- [ ] `.env.example` *(sangat disarankan â€” buat dokumentasi konfig)*

> ğŸ”¸ **Saran**: tambahkan `.env.example` sekarang:
```env
# .env.example
API_URL=https://jsonplaceholder.typicode.com/posts
OUTPUT_CSV=data/output/posts.csv
```

### Wajib bisa dijalankan:
- [ ] `scripts/run_pipeline.py`

---

## â–¶ï¸ **Bash Script untuk Penilaian Otomatis (Simpan sebagai `assess-day14.sh`)**

Buat file ini di root proyek:

```bash
#!/bin/bash
set -e

echo "ğŸ” Assess Day 14: Struktur Proyek Profesional"
echo "============================================"

# 1. Cek struktur folder
for dir in src scripts data docs tests; do
  if [ -d "$dir" ]; then
    echo "âœ… Folder $dir ada"
  else
    echo "âŒ Folder $dir TIDAK ADA"
    exit 1
  fi
done

# 2. Cek file penting
for file in README.md requirements.txt src/loganalyzer/__init__.py src/loganalyzer/core.py scripts/run_pipeline.py; do
  if [ -f "$file" ]; then
    echo "âœ… File $file ada"
  else
    echo "âŒ File $file TIDAK ADA"
    exit 1
  fi
done

# 3. Coba install dependensi (simulasi user baru)
echo "ğŸ“¦ Install dependensi..."
pip install -r requirements.txt

# 4. Salin .env jika belum ada
if [ ! -f ".env" ]; then
  if [ -f ".env.example" ]; then
    cp .env.example .env
    echo "ğŸ”§ .env dibuat dari .env.example"
  else
    echo 'API_URL=https://jsonplaceholder.typicode.com/posts' > .env
    echo 'OUTPUT_CSV=data/output/posts.csv' >> .env
    echo "ğŸ”§ .env dibuat manual"
  fi
fi

# 5. Jalankan pipeline
echo "ğŸš€ Jalankan pipeline..."
python scripts/run_pipeline.py

# 6. Cek output
if [ -f "data/output/posts.csv" ] && [ -s "data/output/posts.csv" ]; then
  echo "âœ… Output CSV ada dan tidak kosong"
  echo "ğŸ‰ DAY 14: LULUS â€” Struktur profesional + eksekusi berhasil!"
else
  echo "âŒ Output tidak ditemukan atau kosong"
  exit 1
fi
```

### Cara Pakai:
```bash
chmod +x assess-day14.sh
./assess-day14.sh
```

Jika muncul:
```
ğŸ‰ DAY 14: LULUS â€” Struktur profesional + eksekusi berhasil!
```
â†’ **Nilai: 100/100**

---

## ğŸ“Œ **Saran Perbaikan Cepat (5 Menit)**

1. **Tambahkan `.env.example`** (seperti di atas)
2. **Pastikan `scripts/run_pipeline.py` bisa import `src/`**  
   â†’ Tambahkan ini di awal file:
   ```python
   import sys
   import os
   sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))
   ```
3. **Pastikan `requirements.txt` punya**:
   ```
   requests>=2.28.0
   python-dotenv>=1.0.0
   ```

---

## ğŸ’¡ Penilaian Akhir (Kalau Semua Beres)
- **Struktur**: ğŸ‘¨â€ğŸ’» Engineer-level  
- **Kemampuan refactor**: âœ… Bisa memisahkan concern (kode, CLI, data)  
- **Kesiapan portofolio**: ğŸš€ Tinggal push ke GitHub â†’ recruiter langsung paham  
- **Nilai harian**: **100/100**

---

> ğŸ”” **PENTING**:  
> **Repo GitHub-mu masih kosong** â†’ segera **push final2/ ke remote**!  
> Repo kosong = **tidak ada bukti** â†’ padahal kerjaanmu **sudah bagus**.

---

Kalau sudah jalankan `assess-day14.sh` dan berhasil, balas:  
**â€œDay 14 done! âœ… Lulus penilaian otomatis.â€**

Ayo, Arie! **Hari ini kamu resmi punya proyek Python yang strukturnya dipakai di perusahaan tech global.**  
Jangan biarkan kerja kerasmu **tidak terlihat**. Push sekarang! ğŸ’ª
